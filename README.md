# Passenger Experience KPI Scorecard (Streamlit)

Interactive dashboard for **Passenger Experience analytics** (KPI scorecard, touchpoint deep-dive, model-driven opportunity prioritization, and segment drilldowns). Built as a portfolio case for **Product Development & Design / Customer Experience analytics** roles.

---

## Live Demo
- **Streamlit App:** https://barata90-passenger-experience-dashboard-1-app-rlcqgz.streamlit.app/ 
- **Repository:** https://github.com/barata90/passenger-experience-dashboard_1

---

## Preview
> Update the image path below to the screenshot you want to feature.

![Dashboard Preview](assets/dashboard.png)

---

## Executive Summary (Leadership-ready)
This dashboard translates passenger survey and operational data into a clear product narrative:

- **Baseline KPI:** Satisfaction rate is ~44% (test set in the original notebook work), indicating meaningful upside for experience improvement.
- **Strong experience linkage:** A composite **Experience Index** (mean of all touchpoint ratings) separates satisfied vs not satisfied passengers clearly.
- **Top opportunities (impact × headroom):** **Inflight Wi‑Fi**, **Online boarding**, and **Check‑in service** emerge as the highest-leverage initiatives from modeling + prioritization.

### Estimated KPI uplift (what-if simulation)
Scenario used for prioritization (not causal): increase a touchpoint rating by **+1** for passengers scoring **≤ 3** (capped at 5), and measure average predicted satisfaction change.

Example estimates from the notebook exports:
- **Inflight Wi‑Fi:** **+1.44 pp**
- **Online boarding:** **+1.00 pp**
- **Check‑in service:** **+0.26 pp**

> These are **scenario estimates** intended for prioritization and stakeholder communication.

---

## What the dashboard includes

### Pages / Tabs
- **Executive View**
  - KPI cards (Satisfaction Rate, Experience Index, passenger count)
  - “Opportunity Map” (performance vs impact) for touchpoints
  - Top opportunities table and what‑if lift (if `outputs/` is present)
  - Download filtered data as CSV (portfolio-friendly)
- **Experience Deep Dive**
  - Bottom touchpoints by average score (pain points)
  - Top touchpoints by satisfaction gap (differentiators)
  - Segment KPIs (Class / Type of Travel / Customer Type)
- **Model & Opportunities**
  - Driver ranking via permutation importance (AUC drop)
  - Opportunity table (importance × headroom)
  - Top‑3 what‑if impact simulation table
- **Segment Drilldown (Multi-page)**
  - Dedicated page to compare **Business vs Personal travel** patterns and touchpoint gaps

---

## Key definitions (used in charts & tables)

- **Satisfaction Rate**
  - Percentage of passengers labeled **satisfied**.
- **Touchpoint Average Score**
  - Mean rating (0–5) for each experience touchpoint.
- **Satisfaction Gap**
  - `avg(touchpoint | satisfied) − avg(touchpoint | not satisfied)`  
  - Higher gap = stronger differentiator for satisfaction.
- **Experience Index**
  - Mean of all touchpoint ratings for each passenger (0–5 scale).
- **Permutation Importance (Driver Strength)**
  - Measures the drop in model AUC when a feature is shuffled.  
  - Higher AUC drop = feature is more predictive.
- **Opportunity Score (Prioritization)**
  - `opportunity_score = importance_mean × score_headroom`
  - `score_headroom = 5 − avg_score_all`
  - Prioritizes touchpoints that are **high impact** and **underperforming**.
- **What‑if Impact Simulation**
  - A transparent scenario: improve low scores (≤3) by +1 and estimate satisfaction lift.  
  - Useful for communicating “expected direction and magnitude” to stakeholders.

---

## Project structure

```
.
├─ app.py
├─ pages/
│  └─ 1_Drilldown_Segments.py
├─ outputs/                         # exported tables (recommended)
├─ assets/                          # screenshots
├─ requirements.txt
├─ test.csv                         # required
├─ initiatives.csv                  # optional (initiative tracking)
└─ README.md
```

### Required
- `app.py`
- `test.csv`
- `requirements.txt`

### Recommended
- `outputs/` (generated by the notebook export) to unlock model-based tables and lift estimates:
  - `permutation_importance_all_features.csv`
  - `touchpoint_opportunity_table.csv`
  - `top3_opportunity_impact_simulation.csv`
  - `touchpoint_scores.csv`, `segment_kpi_*.csv`, etc.

---

## Run locally (Conda, macOS)

```bash
conda create -n qa-dashboard python=3.11 -y
conda activate qa-dashboard
conda install -c conda-forge pandas numpy matplotlib plotly scikit-learn streamlit -y
streamlit run app.py
```

Optional (only if you want to re-run the modeling notebook in the same environment):
```bash
conda install -c conda-forge xgboost shap -y
```

---

## Deployment (Streamlit Community Cloud)
1. Push the repo to GitHub.
2. Go to Streamlit Community Cloud → **New app**
3. Select:
   - **Repo:** this repository
   - **Branch:** `main`
   - **Main file:** `app.py`
4. Deploy and add the live URL to the **Live Demo** section above.

Tip: If you need to force a Python version, add `runtime.txt`:
```
python-3.11
```

---

## Notes on data & cleaning
The app performs lightweight, transparent preprocessing:
- Drops an index-like column (`Unnamed: 0`) if present
- Standardizes categorical labels (`Customer Type`, `Type of Travel`)
- Median-imputes missing `Arrival Delay in Minutes`
- Creates `is_satisfied` and `experience_index` for KPI reporting

---

## How to interpret the Opportunity Map (Executive View)
The Opportunity Map plots each touchpoint by:
- **Performance** (Avg score) on the X-axis
- **Impact** (Satisfaction gap) on the Y-axis

Use the quadrants to prioritize:
- **Low performance + high impact:** highest priority initiatives
- **High performance + high impact:** protect strengths
- **Low performance + low impact:** investigate (may be low leverage)
- **High performance + low impact:** lower priority

---

## Limitations (important for credibility)
- This analysis is **not causal**: model explainability and what‑if lifts reflect association, not guaranteed outcomes.
- Touchpoint ratings are self-reported and can be closely tied to satisfaction labels (inflating predictive performance).
- Treat uplift numbers as **directional** until validated through controlled pilots or experiments.

---

## Portfolio talking points (interview-ready)
1. Defined product KPIs (Satisfaction Rate + Experience Index) and built a leadership scorecard.
2. Identified pain points and differentiators through touchpoint average + satisfaction gap analysis.
3. Built an explainable driver model (permutation importance) to prioritize initiatives.
4. Converted insights into an opportunity table (impact × headroom) and simple what‑if lift estimates.
5. Delivered an interactive dashboard with segment drilldowns and an initiative tracking foundation.

---

## Author
Add your name and links here:
- **Name:** Your Name
- **LinkedIn:** https://www.linkedin.com/in/your-profile
- **Email:** your.email@example.com
- **Portfolio:** https://your-portfolio.com
